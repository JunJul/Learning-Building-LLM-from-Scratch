{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(\n",
    "        url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download \"\n",
    "              \"and extraction.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    #1 Downloads the file\n",
    "    with urllib.request.urlopen(url) as response:    \n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    #2 Unzips the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:    \n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "\n",
    "    #3 Adds a .tsv file extension\n",
    "    os.rename(original_file_path, data_file_path)               \n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    data_file_path, sep = \"\\t\", \n",
    "    header = None, names = [\"Label\", \"Text\"] \n",
    ")\n",
    "\n",
    "#1 Renders the data frame in a Jupyter notebook. Alternatively, use print(df).\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# creating a balanced dataset\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    # 1 Counts the instances of “spam”\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # 2 Randomly samples \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
    "        num_spam, random_state = 123\n",
    "    )\n",
    "\n",
    "    # 3 Combine ham subset with \"spam\"\n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\n",
    "    \"ham\": 0,\n",
    "    \"spam\": 1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    #1 Shuffles the entire DataFrame\n",
    "    df = df.sample(\n",
    "        frac = 1, random_state = 123\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    #2 Calculates split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    #3 Splits the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "#4 Test size is implied to be 0.2 as the remainder.\n",
    "train_df, validation_df, test_df = random_split(\n",
    "    balanced_df, 0.7, 0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special = {\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a Python Datatset class\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length = None,\n",
    "                 pad_token_id = 50256):        \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        #1 Pretokenizes texts\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        #2 Truncates sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        #3 Pads sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype = torch.long),\n",
    "            torch.tensor(label, dtype = torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        \n",
    "        return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file = \"train.csv\",\n",
    "    max_length = None,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating PyTorch data loaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1 This setting ensures compatibility with most computers.\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "\n",
    "#1 Vocabulary size\n",
    "#2 Context length\n",
    "#3 Dropout rate\n",
    "#4 Query-key-value bias\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,          #1\n",
    "    \"context_length\": 1024,       #2\n",
    "    \"drop_rate\": 0.0,             #3\n",
    "    \"qkv_bias\": True              #4\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, \n",
    "                 context_length, dropout,\n",
    "                 num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert(d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # 1\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # 2\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1),\n",
    "        ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # 3\n",
    "        queries = self.W_query(x) # 3\n",
    "        values = self.W_value(x) # 3\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) # 4\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2) # 5\n",
    "        queries = queries.transpose(1, 2) # 5\n",
    "        values = values.transpose(1, 2) # 5\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3) # omega # 6\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens] # 7\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf) # 8\n",
    "\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) # 9\n",
    "        context_vec = context_vec.contiguous().view( # 10\n",
    "            b, num_tokens, self.d_out\n",
    "        )\n",
    "\n",
    "        context_vec = self.out_proj(context_vec) # 11\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        # layers to train the model\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (\n",
    "            1 + torch.tanh(\n",
    "                torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "                (x + 0.044715 * torch.pow(x, 3))\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # multi-head attention\n",
    "        self.att = MultiHeadAttention(\n",
    "            # input dim\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            # output dim\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            # actual input length\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            # number of causal attention \n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            # masking rate\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            # if adding query, key, and value bias\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "\n",
    "        # Apply layers and activation function to train the model\n",
    "        self.ff = FeedForward(cfg)\n",
    "\n",
    "        # normalization\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # masking\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 1\n",
    "\n",
    "        # assgin input as shortcut\n",
    "        shortcut = x\n",
    "\n",
    "        # normalize input\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # get context vector\n",
    "        x = self.att(x)\n",
    "\n",
    "        # dropout\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        # shortcut: add input to output \n",
    "        x = x + shortcut # 2\n",
    "\n",
    "        # assgin transformed input to shortcut \n",
    "        shortcut = x # 3\n",
    "\n",
    "        # normalizing\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        # apply linear layers and activation functions to input\n",
    "        x = self.ff(x)\n",
    "\n",
    "        # drop\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        # shortcut: add input to output \n",
    "        x = x + shortcut # 4\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # create token embeddings\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "\n",
    "        # create positional embeddings\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "\n",
    "        # set drop out rate\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Apply transfomer block with n_layers\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        # Apply layer normalization to embedding layers\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "\n",
    "        # create output layers\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "\n",
    "        # create token embeddings\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        # create positional embeddings\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device = in_idx.device) # 1\n",
    "        )\n",
    "        \n",
    "        # combine token and positional embeddings\n",
    "        x = tok_embeds + pos_embeds\n",
    "\n",
    "        # drop some layers\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        # apply transformer blocksbb\n",
    "        x = self.trf_blocks(x)\n",
    "\n",
    "        # normalizing\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        # apply linear function to x and return probbaility of each token and text\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx,  # 1\n",
    "                         max_new_tokens, context_size):\n",
    "    \n",
    "    # iterate number of max new tokens provided\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # extract last number of context size\n",
    "        idx_cond = idx[:, -context_size:] # 2\n",
    "\n",
    "        # Disables gradient tracking since we are not training yet\n",
    "        with torch.no_grad():\n",
    "            # Obtain logits\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # only extract the last row from a tensor\n",
    "        logits = logits[:, -1, :] # 3\n",
    "\n",
    "        # Obtain probability through softmax\n",
    "        # Probability of each token in vocabulary\n",
    "        probas = torch.softmax(logits, dim = -1) # 4\n",
    "        \n",
    "        # find the max probability\n",
    "        idx_next = torch.argmax(probas, dim = -1, keepdim = True) # 5\n",
    "        \n",
    "        # find the index corresponding to the max proba\n",
    "        idx = torch.cat((idx, idx_next), dim = 1) # 6\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    # 1\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    # 2\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                         \"Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):           \n",
    "    #1 Sets the model’s positional and token embedding weights to those specified in params.\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    #2 Iterates over each transformer block in the model\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "\n",
    "        #3 The np.split function is used to divide the attention and bias weights into \n",
    "        # three equal parts for the query, key, and value components.\n",
    "\n",
    "        # attention weights\n",
    "        q_w, k_w, v_w = np.split(                            \n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        # bias weights\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        # weight tensor for the output projection layer\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # weight and bias from layers\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # normalizing \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    #4 he original GPT-2 model by OpenAI reused the token embedding weights in the output layer to \n",
    "    # reduce the total number of parameters, which is a concept known as weight tying.\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    # 1 Logits of last output token\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    # calculate the cross entropy\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "#1 Iteratives over all batches if no fixed num_batches is specified\n",
    "#2 Reduces the number of batches to match the total number of batches in the data loader if num_batches exceeds the number of batches in the data loader\n",
    "#3 Sums loss for each batch\n",
    "#4 Averages the loss over all batches\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)     #1\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))   #2\n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()    #3\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches    #4\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, \n",
    "                   device, eval_iter):\n",
    "    # 1 Dropout is disabled during evaluation for stable, reproducible results.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 2 Disables gradient tracking, which is not required during evaluation, \n",
    "        #   to reduce the computational overhead\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches = eval_iter\n",
    "        )\n",
    "        \n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches = eval_iter\n",
    "        )\n",
    "    \n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "setting, params = download_and_load_gpt2(\n",
    "    model_size = model_size,\n",
    "    models_dir = \"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768, padding_idx=768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens = 15,\n",
    "    context_size = BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially seleceted to recevice $1000 cash or $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "# Before fine-tuning the model as a spam classifier\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" seleceted to recevice $1000 cash or $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens = 23,\n",
    "    context_size = BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768, padding_idx=768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the model meaning that we make all layers nontrainable\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a classification layer\n",
    "\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features = BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features = num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the final LayerNORM AND last transformer block trainable, we set their respective requires_grad to True\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:  tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning the whole model\n",
    "\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs: \", inputs)\n",
    "\n",
    "# 1 shape: (batch_size, num_tokens)\n",
    "print(\"Inputs dimensions: \", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: \n",
      " tensor([[[-1.5883,  0.9920],\n",
      "         [-3.7208,  7.4510],\n",
      "         [-2.2642,  6.6005],\n",
      "         [-3.5965,  3.9889]]])\n",
      "Outputs dimensions:  torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "print(\"Outputs: \\n\", outputs)\n",
    "print(\"Outputs dimensions: \", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token:  tensor([[-3.5965,  3.9889]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token: \", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5965,  3.9889]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches = None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Ensures number of batches doesn’t exceed batches in data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # .to(device): use GPU or CPU\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Logits of last output token\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "\n",
    "                # find the predicted labels with max softmax probabilities \n",
    "                #   that only has two values in a vector\n",
    "                predicted_labels = torch.argmax(logits, dim = -1)\n",
    "            \n",
    "            # find the number of labels\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "\n",
    "            # find the correct prediction\n",
    "            correct_predictions += (\n",
    "                (predicted_labels == target_batch).sum().item()\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # return average accuracy\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches = 10\n",
    ")\n",
    "\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches = 10\n",
    ")\n",
    "\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches = 10\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loder(data_loader, model, device, num_batches = None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 1 Ensures number of batches doesn’t exceed batches in data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # iterate every single batch to calculate the loss values\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            # add all loss values\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    # return the average loss value\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.445\n",
      "Validation loss: 2.575\n",
      "Test loss: 2.314\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loder(\n",
    "        train_loader, model, device, num_batches = 5\n",
    "    )\n",
    "\n",
    "    val_loss = calc_loss_loder(val_loader, model, device, num_batches = 5)\n",
    "    test_loss = calc_loss_loder(test_loader, model, device, num_batches = 5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "        model, train_loader, val_loader, \n",
    "        optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    \n",
    "    # 1 Initialize lists to track losses and examples seen\n",
    "\n",
    "    # training and validation loss\n",
    "    # training exmaples seen, validation examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    \n",
    "    # 2 Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # 3 Sets model to training mode\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 4 Resets loss gradients from the previous batch iteration\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "\n",
    "            # 5 Calculates loss gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # 6 Updates model weights using loss gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # 7 New: tracks examples instead of tokens\n",
    "            examples_seen += input_batch.shape[0]\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            # 8 Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        \n",
    "        # 9 Calculates accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.146, Val loss 2.383\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.524, Val loss 0.558\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.354\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.334, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.341, Val loss 0.308\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.144, Val loss 0.210\n",
      "Ep 4 (Step 000450): Train loss 0.157, Val loss 0.136\n",
      "Ep 4 (Step 000500): Train loss 0.224, Val loss 0.139\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.145\n",
      "Ep 5 (Step 000600): Train loss 0.085, Val loss 0.075\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 10.12 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5, weight_decay = 0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, exmaples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, \n",
    "    device, num_epochs = num_epochs, eval_freq = 50,\n",
    "    eval_iter = 5\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1 Plots training and validation loss against epochs\n",
    "#2 Creates a second x-axis for examples seen\n",
    "#3 Invisible plot for aligning ticks\n",
    "#4 Adjusts layout to make room\n",
    "\n",
    "def plot_values(\n",
    "        epochs_seen, examples_seen, train_values, val_values,\n",
    "        label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    " #1\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_values, linestyle=\"-.\",\n",
    "        label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    " #2\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)    #3\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()             #4\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, exmaples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, exmaples_seen, len(train_accs))\n",
    "\n",
    "plot_values(\n",
    "    epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
    "    label=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.12%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "        text, model, tokenizer, device, max_length = None,\n",
    "        pad_token_id = 50256):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    # 1 Prepares inputs to the model\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    # 2 Truncates sequences if they are too long\n",
    "    inputs_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # 3 Pads sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\n",
    "    # 4 Adds batch dimension\n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device = device\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "    #5 Models inference without gradient tracking\n",
    "    with torch.no_grad():\n",
    "        #6 Logits of the last output toke                               \n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    #7 Returns the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\42128\\AppData\\Local\\Temp\\ipykernel_41708\\379311099.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"review_classifier.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
